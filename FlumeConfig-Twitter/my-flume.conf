# Single node flume config
# source -> Twitter
# channel -> memory
# sink -> hdfs

# Name the components on this agent
myagent.sources = twitter_source
myagent.sinks = hdfs_sink
myagent.channels = kafka_channel

# Describe/configure the source
myagent.sources.twitter_source.type = com.cloudera.flume.source.TwitterSource
myagent.sources.twitter_source..keywords = hadoop,hive,beer,analytics,Business Intelligence,
myagent.sources.twitter_source.consumerKey = <consumer key>
myagent.sources.twitter_source.consumerSecret = <consumer secrete>
myagent.sources.twitter_source.accessToken = <accessToken>
myagent.sources.twitter_source.accessTokenSecret = <accessTokenSecret>

# Describe the sink
myagent.sinks.hdfs_sink.type = hdfs
myagent.sinks.hdfs_sink.hdfs.path = /user/cloudera/twitter_db/tweets/twitted_on=%y-%m-%d/
myagent.sinks.hdfs_sink.hdfs.filePrefix = tweets_
myagent.sinks.hdfs_sink.hdfs.inUsePrefix = .
myagent.sinks.hdfs_sink.hdfs.fileType = DataStream
myagent.sinks.hdfs_sink.hdfs.writeFormat = Text
myagent.sinks.hdfs_sink.hdfs.batchSize = 10000
myagent.sinks.hdfs_sink.hdfs.rollSize = 10000000
myagent.sinks.hdfs_sink.hdfs.rollInterval=0
myagent.sinks.hdfs_sink.hdfs.rollCount=0

# use kafka as channel

myagent.channels.kafka_channel.type   = org.apache.flume.channel.kafka.KafkaChannel
myagent.channels.kafka_channel.capacity = 10000
myagent.channels.kafka_channel.transactionCapacity = 1000
myagent.channels.kafka_channel.brokerList=localhost:9092
myagent.channels.kafka_channel.topic=twitter_test_1
myagent.channels.kafka_channel.zookeeperConnect=localhost:2182

# Bind the source and sink to the channel
myagent.sources.twitter_source.channels = kafka_channel
myagent.sinks.hdfs_sink.channel = kafka_channel
